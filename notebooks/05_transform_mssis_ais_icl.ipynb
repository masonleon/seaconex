{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "import json\n",
    "\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading sample AIS data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = gpd.read_file('../data/interim/mssis-ais-records_v2.gpkg')\n",
    "wgs84 = df.crs\n",
    "print(\"Finished reading {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wpi = gpd.read_file('../data/interim/nga-wpi_v1.gpkg')\n",
    "wgs84 = wpi.crs\n",
    "print(\"Finished reading {}\".format(len(wpi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpi.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpi.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICL TAC1 Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.service_id == 'TAC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert wpi from gpd.GeoDataFrame to pd.DataFrame so they can be joined and result is a GeoDataFrame\n",
    "ports_wpi = pd.DataFrame(wpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_wpi.drop(\n",
    "    columns=[\n",
    "#         'portNumber',\n",
    "#         'portName',\n",
    "#         'regionNumber',\n",
    "#         'regionName',\n",
    "#         'countryCode',\n",
    "#         'countryName',\n",
    "#         'publicationNumber',\n",
    "        'chartNumber',\n",
    "        'navArea',\n",
    "        'harborSize',\n",
    "        'harborType',\n",
    "        'globalId',\n",
    "        'dnc',\n",
    "#         'alternateName',\n",
    "#         's23WaterBody'\n",
    "        'geometry'\n",
    "    ], \n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_wpi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports_wpi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join ais and nga wpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(left=df, right=wpi, how='left', left_on=['mssis_wpi'], right_on=['portNumber'], suffixes=('_ais', '_nga_wpi')).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(left=df, right=wpi, how='left', left_on=['mssis_wpi'], right_on=['portNumber'], suffixes=('_ais', '_nga_wpi'))\n",
    "\n",
    "df = pd.merge(left=df, right=ports_wpi, how='left', left_on=['mssis_wpi'], right_on=['portNumber'], suffixes=('_ais', '_nga_wpi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['mssis_eez', 'mssis_ao', 'mssis_wpi']).size().reset_index().rename(columns={0:'ais_count'}).sort_values('ais_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['mssis_eez', 'mssis_ao', 'mssis_wpi', 'portName', 'countryName']).size().reset_index().rename(columns={0:'ais_count'}).sort_values('ais_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['ais_time'])\n",
    "df = df.set_index('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ais_sog'].hist(bins=100, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original size: {} rows\".format(len(df)))\n",
    "df = df[df.ais_sog>0]\n",
    "print(\"Reduced to {} rows after removing 0 speed records\".format(len(df)))\n",
    "df['ais_sog'].hist(bins=100, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vessel_name'].value_counts().plot(kind='bar', figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['portName'].value_counts().plot(kind='bar', figsize=(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create trajectories for each vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgs84 = df.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MIN_LENGTH = 100 # meters\n",
    "traj_collection = mpd.TrajectoryCollection(df, 'vessel_mmsi', min_length=MIN_LENGTH)\n",
    "print(\"Finished creating {} trajectories\".format(len(traj_collection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection = mpd.MinTimeDeltaGeneralizer(traj_collection).generalize(tolerance=timedelta(minutes=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/28999287/generate-random-colors-rgb\n",
    "# import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "mmsi_colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(df.vessel_mmsi.unique().size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsi_list = df.vessel_mmsi.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsi_to_color = dict(zip(mmsi_list, mmsi_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmsi_to_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection.plot(column='vessel_mmsi', column_to_color=mmsi_to_color, linewidth=1, capstyle='round')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection.hvplot(title='vessel_mmsi', line_width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj_collection.trajectories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj_collection.trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection.trajectories[0].df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_pursuit = traj_collection.trajectories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_pursuit.hvplot(title='Trajectory {}'.format(str(independent_pursuit.id)), height=300, line_width=5.0, c='ais_sog', cmap='Dark2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for traj in traj_collection:\n",
    "    traj.add_speed\n",
    "#     print(traj.to_linestring())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_pursuit.to_linestring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_pursuit.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_pursuit.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = mpd.ObservationGapSplitter(traj_collection).split(gap=timedelta(minutes=5))\n",
    "# print(\"Extracted {} individual trips from {} continuous vessel tracks\".format(len(independent_pursuit_trips), len(independent_pursuit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.hvplot(title='trips', line_width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_pursuit.df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traj_to_timestamped_geojson(trajectory_collection):\n",
    "    features = []\n",
    "    \n",
    "    for trajectory in traj_collection.trajectories:\n",
    "    \n",
    "        df = trajectory.df.copy()\n",
    "        df[\"previous_geometry\"] = df[\"geometry\"].shift()\n",
    "        df[\"time\"] = df.index\n",
    "        df[\"previous_time\"] = df[\"time\"].shift()\n",
    "        \n",
    "        for _, row in df.iloc[1:].iterrows():\n",
    "            coordinates = [\n",
    "                [\n",
    "                    row[\"previous_geometry\"].xy[0][0],\n",
    "                    row[\"previous_geometry\"].xy[1][0]\n",
    "                ],\n",
    "                [\n",
    "                    row[\"geometry\"].xy[0][0],\n",
    "                    row[\"geometry\"].xy[1][0]\n",
    "                ]\n",
    "            ]\n",
    "            times = [row[\"previous_time\"].isoformat(), row[\"time\"].isoformat()]\n",
    "            data = row.to_dict()\n",
    "            data.pop('geometry', None)\n",
    "            features.append(\n",
    "                {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": {\n",
    "                        \"type\": \"LineString\",\n",
    "                        \"coordinates\": coordinates,\n",
    "                    },\n",
    "                    \"properties\": {\n",
    "                        \"times\": times,\n",
    "    #                     \"style\": {\n",
    "    # #                         \"color\": mmsi_to_color[\"vessel_mmsi\"],\n",
    "    #                         \"weight\": 5,\n",
    "    #                     },\n",
    "                        \"vessel_mmsi\": row[\"vessel_mmsi\"],\n",
    "#                          'ais_sog',\n",
    "#                          'ais_heading',\n",
    "#                          'mssis_wpi',\n",
    "#                          'mssis_eez',\n",
    "#                          'mssis_ao',\n",
    "                         \n",
    "                         \"vessel_name\": row[\"vessel_name\"],\n",
    "#                          'vessel_call_sign',\n",
    "#                          'vessel_build_year',\n",
    "#                          'vessel_gross_tonnage',\n",
    "#                          'vessel_type',\n",
    "#                          'vessel_flag_country',\n",
    "                         \"vessel_capacity_teu\": row[\"vessel_capacity_teu\"],\n",
    "#                          'vessel_capacity_vehicle_units',\n",
    "#                          'vessel_stern_ramp_capacity_tons',\n",
    "                         \"carrier_id_fk\": row[\"carrier_id_fk\"],\n",
    "                         \"service_id\": row[\"service_id\"],\n",
    "#                          'geometry',\n",
    "                         \"nga_wpi\": row[\"portNumber\"],\n",
    "                         \"nga_wpi_port_name\":row[\"portName\"],\n",
    "#                          'regionNumber',\n",
    "#                          'regionName',\n",
    "#                          'countryCode',\n",
    "#                          'countryName',\n",
    "#                          'publicationNumber',\n",
    "#                          'alternateName',\n",
    "#                          's23WaterBody']\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_to_timestamped_geojson(independent_pursuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_features = list()\n",
    "\n",
    "# for t in traj_collection:\n",
    "#     features.append(traj_to_timestamped_geojson(traj))\n",
    "    \n",
    "# geojson = {\n",
    "#   \"type\": \"FeatureCollection\",\n",
    "#   \"features\": features\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_features = []\n",
    "\n",
    "# for t in traj_collection.trajectories:\n",
    "#     traj_features.append(\n",
    "#         #         {\n",
    "#         #             \"type\": \"FeatureCollection\",\n",
    "#         #             \"features\": traj_to_timestamped_geojson(traj)\n",
    "#         #         }\n",
    "#         traj_to_timestamped_geojson(traj_features, t)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": traj_to_timestamped_geojson(traj_collection)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features:\n",
    "#     geojson = {\n",
    "#       \"type\": \"FeatureCollection\",\n",
    "#       \"features\": features\n",
    "#     }\n",
    "    \n",
    "#     out.append(geojson)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '../data/interim/timestamped-trajectory-icl-tac1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path + '.json', 'w') as json_file:\n",
    "    json.dump(geojson, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path + '.geojson', 'w') as json_file:\n",
    "    json.dump(geojson, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xy = t.get_start_location()\n",
    "# m = folium.Map(location=[xy.y, xy.x], zoom_start=14)\n",
    "\n",
    "# TimestampedGeoJson(\n",
    "#     {\n",
    "#         \"type\": \"FeatureCollection\",\n",
    "#         \"features\": features,\n",
    "#     },\n",
    "#     period=\"PT1S\",\n",
    "#     add_last_point=True,\n",
    "#     transition_time=10\n",
    "# ).add_to(m)\n",
    "\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jingwen-z.github.io/how-to-draw-a-variety-of-maps-with-folium-in-python/\n",
    "i=0\n",
    "for mmsi in mmsi_list:\n",
    "    color_dict[mmsi] = {\n",
    "        'MMSI': mmsi,\n",
    "        'color': color[i],\n",
    "        'feature': folium.FeatureGroup(\n",
    "                      name=mmsi,\n",
    "                      show=False\n",
    "                  )\n",
    "    }\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in geo_df.iterrows():\n",
    "    \n",
    "    if row['MMSI'] == 211256150:\n",
    "        mmsi = row['MMSI']\n",
    "        c = color_dict[mmsi]['color']\n",
    "\n",
    "        folium.CircleMarker(\n",
    "#             location=[row.geometry.y, row.geometry.x],\n",
    "            radius='1',\n",
    "            #color=c,\n",
    "            #fill_color=c,\n",
    "            color='red',\n",
    "            fill_color='red',\n",
    "            fill=True\n",
    "        ).add_to(color_dict[mmsi]['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in color_dict.items():\n",
    "    v['feature'].add_to(ais_map)\n",
    "\n",
    "folium.LayerControl(\n",
    "    name='MMSI',\n",
    "    collapsed=True\n",
    ").add_to(ais_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_map['t'] = pd.to_datetime(df['TimeOfFix'], unit='s')\n",
    "df = df.set_index('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# df = read_file('../data/ais.gpkg')\n",
    "wgs84 = df.crs\n",
    "print(\"Finished reading {}\".format(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TimeOfFix.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TimeOfFix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the DataFrame to Trajectories we need to create a temporal index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t'] = pd.to_datetime(df['TimeOfFix'], unit='s')\n",
    "df = df.set_index('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the data distributions, we can see that there are a lot of records with speed over ground (SOG) values of zero in this dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SOG'].hist(bins=100, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of these rows with zero SOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original size: {} rows\".format(len(df)))\n",
    "df = df[df.SOG>0]\n",
    "print(\"Reduced to {} rows after removing 0 speed records\".format(len(df)))\n",
    "df['SOG'].hist(bins=100, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of ships we have in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['ShipType'].value_counts().plot(kind='bar', figsize=(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "MIN_LENGTH = 100 # meters\n",
    "traj_collection = mpd.TrajectoryCollection(df, 'MMSI', min_length=MIN_LENGTH)\n",
    "print(\"Finished creating {} trajectories\".format(len(traj_collection)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_collection = mpd.MinTimeDeltaGeneralizer(traj_collection).generalize(tolerance=timedelta(minutes=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting trajectories\n",
    "\n",
    "Let's give the most common ship types distinct colors. The remaining ones will be just grey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shiptype_to_color = {'Passenger': 'blue', 'HSC': 'green', 'Tanker': 'red', 'Cargo': 'orange'}\n",
    "# traj_collection.plot(column='ShipType', column_to_color=shiptype_to_color, linewidth=1, capstyle='round')\n",
    "traj_collection.plot(column='MMSI', linewidth=1, capstyle='round')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passenger = traj_collection.filter('ShipType', 'Passenger')\n",
    "# passenger.hvplot(title='Passenger ferries', line_width=2)\n",
    "# vessels = traj_collection\n",
    "traj_collection.hvplot(title='All', line_width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing trajectory properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot individual trajectories to better visualize their properties, such as the changes in NavStatus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_traj = traj_collection.trajectories[0]\n",
    "my_traj.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_traj.df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_traj.hvplot(title='Trajectory {}'.format(str(my_traj.id)), height=300, line_width=5.0, c='NavStatus', cmap='Dark2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding ships passing under Älvsborgsbron bridge\n",
    "We can find ships passing under the bridge based on trajectory intersections with the bridge area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = Polygon([(11.89935, 57.69270), (11.90161, 57.68902), (11.90334, 57.68967), (11.90104, 57.69354), (11.89935, 57.69270)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersecting = traj_collection.get_intersecting(area_of_interest)\n",
    "print(\"Found {} intersections\".format(len(intersecting)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge_traj = intersecting.trajectories[0]\n",
    "bridge_traj.hvplot(title='Trajectory {}'.format(str(bridge_traj.id)), height=300, line_width=5.0, c='NavStatus', cmap='Dark2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge_traj.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying trip origins and destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since AIS records with a speed over ground (SOG) value of zero have been removed from the dataset, we can use the `split_by_observation_gap()` function to split the continuous observations into individual trips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = mpd.ObservationGapSplitter(passenger).split(gap=timedelta(minutes=5))\n",
    "print(\"Extracted {} individual trips from {} continuous vessel tracks\".format(len(trips), len(passenger)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the resulting trips!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.hvplot(title='Passenger ferry trips', line_width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to plotting the original continuous observations, this visualization is much cleaner because there are no artifacts at the border of the area of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's get the trip origins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = trips.get_start_locations()\n",
    "origins.hvplot(title='Trip origins by ship type', c='Name', geo=True, tiles='OSM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data sample, trip origins can be:\n",
    "- When a ship departs its anchoring location and the speed changes from 0 to >0\n",
    "- When a ship trajectory first enters the observation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins.hvplot(title='Origins by speed', c='SOG', geo=True, tiles='OSM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding ships that depart from Sjöfartsverket (Maritime Administration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = mpd.ObservationGapSplitter(traj_collection).split(gap=timedelta(minutes=5))\n",
    "area_of_interest = Polygon([(11.86815, 57.68273), (11.86992, 57.68047), (11.87419, 57.68140), (11.87288, 57.68348), (11.86815, 57.68273)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify vessels that start their trip within a given area of interest by intersecting trip starting locations with our area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departures = []\n",
    "for traj in trips:\n",
    "    if traj.get_start_location().intersects(area_of_interest) and traj.get_length() > 100:\n",
    "        departures.append(traj)\n",
    "print(\"Found {} departures\".format(len(departures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departures[1].hvplot(title='Trajectory {}'.format(departures[1].id), line_width=5, c='Name', cmap='Dark2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of ships depart from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for traj in departures:\n",
    "    print(\"{} vessel '{}' departed at {}\".format(traj.df['ShipType'].iloc[0], traj.df['Name'].iloc[0], traj.get_start_time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the same works for arrivals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals = []\n",
    "for traj in trips:\n",
    "    if traj.get_end_location().intersects(area_of_interest) and traj.get_length() > 100:\n",
    "        arrivals.append(traj)\n",
    "print(\"Found {} arrivals\".format(len(arrivals)))\n",
    "\n",
    "for traj in arrivals:\n",
    "    print(\"{} vessel '{}' arrived at {}\".format(traj.df['ShipType'].iloc[0], traj.df['Name'].iloc[0], traj.get_end_time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering origins\n",
    "\n",
    "To run this section, you need to have the scikit-learn package installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import great_circle\n",
    "from shapely.geometry import MultiPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = trips.get_start_locations()\n",
    "origins['lat'] = origins.geometry.y\n",
    "origins['lon'] = origins.geometry.x\n",
    "matrix = origins[['lat','lon']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms_per_radian = 6371.0088\n",
    "epsilon = 0.1 / kms_per_radian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=epsilon, min_samples=1, algorithm='ball_tree', metric='haversine').fit(np.radians(matrix))\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = len(set(cluster_labels))\n",
    "clusters = pd.Series([matrix[cluster_labels == n] for n in range(num_clusters)])\n",
    "print('Number of clusters: {}'.format(num_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centermost_point(cluster):\n",
    "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "    return Point(tuple(centermost_point)[1], tuple(centermost_point)[0])\n",
    "centermost_points = clusters.map(get_centermost_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins.hvplot(title='Clustered origins', c='cluster', geo=True, tiles='OSM', cmap='glasbey_dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_by_cluster = pd.DataFrame(origins).groupby(['cluster'])\n",
    "summary = origins_by_cluster['ShipType'].unique().to_frame(name='types')\n",
    "summary['n'] = origins_by_cluster.size()\n",
    "summary['symbol_size'] = summary['n']*10 # for visualization purposes\n",
    "summary['sog'] = origins_by_cluster['SOG'].mean()\n",
    "summary['geometry'] = centermost_points\n",
    "summary = summary[summary['n']>1].sort_values(by='n', ascending=False)\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_of_interest_id = 28\n",
    "origins[origins['cluster']==cluster_of_interest_id].hvplot(\n",
    "    title='Cluster {}'.format(cluster_of_interest_id), c='ShipType', geo=True, tiles='OSM', height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( trips.hvplot(title='Origin clusters by speed', color='gray', line_width=1) *\n",
    "  GeoDataFrame(summary, crs=wgs84).hvplot(c='sog', size='symbol_size', geo=True,  cmap='RdYlGn')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue exploring MovingPandas\n",
    "\n",
    "\n",
    "1. [Ship data analysis](2-ship-data.ipynb)\n",
    "2. [Bird migration analysis](1-bird-migration.ipynb)\n",
    "3. [Horse collar data exploration](3-horse-collar.ipynb)\n",
    "4. [Stop hotspot detection](4-stop-hotspots.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
