{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaconex\n",
    "\n",
    "import camelot\n",
    "import requests\n",
    "import time\n",
    "import lxml\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import fiona\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from shapely.geometry import Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-malta",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminals_gdf = gpd.read_file(\n",
    "    '../data/processed/terminals.geojson'\n",
    ")\n",
    "\n",
    "terminals_gdf['longitude'] = terminals_gdf.geometry.apply(lambda p: p.x)\n",
    "terminals_gdf['latitude'] = terminals_gdf.geometry.apply(lambda p: p.y)\n",
    "\n",
    "terminals_gdf.drop(\n",
    "    columns=['geometry'],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminals_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_gdf = gpd.read_file(\n",
    "    '../data/interim/master_schedules_edges.geojson'\n",
    ")[['transport_edge_no', 'terminal_call_facility_1', 'terminal_call_facility_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_gdf = routes_gdf.merge(\n",
    "#     left=routes_2,\n",
    "    right=terminals_gdf[['terminal', 'latitude', 'longitude']].add_suffix('_1'),\n",
    "    how='left', \n",
    "    left_on=['terminal_call_facility_1'], \n",
    "    right_on=['terminal_1']\n",
    ").merge(\n",
    "#     left=routes_2,\n",
    "    right=terminals_gdf[['terminal', 'latitude', 'longitude']].add_suffix('_2'),\n",
    "    how='left', \n",
    "    left_on=['terminal_call_facility_2'], \n",
    "    right_on=['terminal_2']\n",
    ").drop(\n",
    "    columns=['terminal_1', 'terminal_2', 'terminal_call_facility_1','terminal_call_facility_2'],\n",
    ").rename(\n",
    "    columns={\n",
    "        'latitude_1':'olat', \n",
    "        'longitude_1': 'olon',\n",
    "        'latitude_2':'dlat', \n",
    "        'longitude_2': 'dlon',\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "routes_gdf.to_csv(\n",
    "    '../data/searoute/data/in/searoutes.csv', \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# routes_2.columns=['transport_edge_no','olon','olat','dlon','dlat']\n",
    "# routes_2['obj_type'] = 'searoute_terminal_call_edge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "searoutes = gpd.read_file('../data/interim/master_schedules_edges.json')[['transport_edge_no', 'terminal_call_facility_1', 'terminal_call_facility_2']]\n",
    "\n",
    "searoutes.merge(\n",
    "    right=terminals_df[['terminal', 'latitude', 'longitude']].add_suffix('_1'),\n",
    "    how='left', \n",
    "    left_on=['terminal_call_facility_1'], \n",
    "    right_on=['terminal_1']\n",
    "# ).drop(\n",
    "#     columns=['terminal_1']\n",
    "# ).reset_index(\n",
    "#     drop=True\n",
    ").merge(\n",
    "    right=terminals_df[['terminal', 'latitude', 'longitude']].add_suffix('_2'),\n",
    "    how='left', \n",
    "    left_on=['terminal_call_facility_2'], \n",
    "    right_on=['terminal_2']\n",
    ").drop(\n",
    "    columns=[\n",
    "        'terminal_1',\n",
    "        'terminal_2',\n",
    "        'terminal_call_facility_1',\n",
    "        'terminal_call_facility_2'\n",
    "    ]\n",
    "# ).reset_index(\n",
    "#     drop=True\n",
    ").rename(\n",
    "    columns={\n",
    "        'transport_edge_no':'route name',\n",
    "        'latitude_1':'olat',\n",
    "        'longitude_1':'olon',\n",
    "        'latitude_2': 'dlat',\n",
    "        'longitude_2':'dlon'\n",
    "    }\n",
    ")[['route name','olon','olat','dlon','dlat']].to_csv(\n",
    "    path_or_buf='../data/searoute/data/in/searoutes.csv',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-spirit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "searoutes = gpd.read_file('../data/interim/master_schedules_edges.json')[['transport_edge_no', 'terminal_call_facility_1', 'terminal_call_facility_2']]\n",
    "\n",
    "searoutes.merge(\n",
    "    right=terminals_df[['terminal', 'latitude', 'longitude']].add_suffix('_1'),\n",
    "    how='left', \n",
    "    left_on=['terminal_call_facility_1'], \n",
    "    right_on=['terminal_1']\n",
    "# ).drop(\n",
    "#     columns=['terminal_1']\n",
    "# ).reset_index(\n",
    "#     drop=True\n",
    ").merge(\n",
    "    right=terminals_df[['terminal', 'latitude', 'longitude']].add_suffix('_2'),\n",
    "    how='left', \n",
    "    left_on=['terminal_call_facility_2'], \n",
    "    right_on=['terminal_2']\n",
    ").drop(\n",
    "    columns=[\n",
    "        'terminal_1',\n",
    "        'terminal_2',\n",
    "        'terminal_call_facility_1',\n",
    "        'terminal_call_facility_2'\n",
    "    ]\n",
    "# ).reset_index(\n",
    "#     drop=True\n",
    ").rename(\n",
    "    columns={\n",
    "        'transport_edge_no':'route name',\n",
    "        'latitude_1':'olat',\n",
    "        'longitude_1':'olon',\n",
    "        'latitude_2': 'dlat',\n",
    "        'longitude_2':'dlon'\n",
    "    }\n",
    ")[['route name','olon','olat','dlon','dlat']].to_csv(\n",
    "    path_or_buf='../data/searoute/data/in/searoutes.csv',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
